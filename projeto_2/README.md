# üß† Projeto 2 ‚Äî Previs√£o de S√©ries Temporais: Deep Learning vs. Estat√≠stica

üì¢ **Apresenta√ß√£o (Slides):** [Clique aqui para visualizar (PDF)](./time-series.pdf)

## üéØ Objetivo
Atendendo aos requisitos da disciplina, o objetivo central deste projeto √© realizar um **estudo comparativo** de desempenho na previs√£o de s√©ries temporais entre duas abordagens distintas:
1.  **Modelagem Estat√≠stica (Baseline):** utilizando o modelo **ARIMA**, j√° explorado no Projeto 1.
2.  **Machine Learning (Deep Learning):** implementando uma rede neural recorrente do tipo **LSTM (Long Short-Term Memory)**.

O foco √© analisar se a capacidade da LSTM de capturar n√£o-linearidades e depend√™ncias de longo prazo supera a abordagem linear cl√°ssica na previs√£o de emiss√µes globais.

## üóÇÔ∏è Dataset
Foi utilizado o mesmo conjunto de dados base do projeto anterior, **CO‚ÇÇ Emissions** ([Kaggle](https://www.kaggle.com/datasets/ulrikthygepedersen/co2-emissions-by-country)), contendo a s√©rie anual de emiss√µes globais (`total_ghg`) de **1850 a 2023**.

## ‚öôÔ∏è Pr√©-processamento e Engenharia de Features
Diferente da abordagem estat√≠stica, as redes neurais exigem uma prepara√ß√£o espec√≠fica dos dados:

- **Normaliza√ß√£o (StandardScaler):**
  a s√©rie foi padronizada (m√©dia 0, desvio padr√£o 1) para facilitar a converg√™ncia do gradiente durante o treinamento da rede neural.
- **Janela Deslizante (Sliding Window):**
  a s√©rie temporal foi transformada em um problema de aprendizado supervisionado.
  - **Window Size (Lag):** 3 anos (os 3 valores passados s√£o usados para prever o pr√≥ximo).
  - Isso gerou pares de entrada ($X$) e sa√≠da ($y$) para o modelo.
- **Divis√£o de Dados:**
  - **Treino:** ~80% (139 amostras).
  - **Teste:** ~20% (35 amostras), respeitando a ordem cronol√≥gica para evitar *data leakage*.
- **Tensores:** convers√£o dos dados para tensores do **PyTorch**.

## üß† Arquitetura da Rede (LSTM)
Optou-se pela **LSTM** em vez de uma RNN simples (Vanilla) para mitigar o problema do *Vanishing Gradient* e permitir que o modelo aprendesse tend√™ncias seculares (desde 1850) sem "esquecer" o passado distante.

| Camada | Configura√ß√£o |
|---------|-------------|
| **Entrada** | Input Size = 1 (univariado) |
| **LSTM** | Hidden Size = 32, Layers = 1 |
| **Fully Connected** | Linear (32 $\to$ 1) para a previs√£o final |
| **Otimizador** | Adam (Learning Rate = 1e-3) |
| **Fun√ß√£o de Perda** | MSE (Mean Squared Error) |
| **√âpocas** | 1000 |

## üìä Avalia√ß√£o de Desempenho
Para validar a efic√°cia do Machine Learning, os resultados da LSTM foram comparados diretamente com o modelo **ARIMA** (baseline estat√≠stico) no mesmo conjunto de teste (√∫ltimos 32 anos alinhados).

| Modelo | MSE | RMSE | MAE | R¬≤ |
|:--|--:|--:|--:|--:|
| **LSTM** (Deep Learning) | **2.48 √ó 10‚Å∂** | **1576.1** | **1319.5** | **0.92** |
| **ARIMA** (Estat√≠stico) | 3.02 √ó 10‚Å∑ | 5497.8 | 4655.3 | 0.02 |

### üìà Comparativo de Melhoria
A abordagem com LSTM apresentou um ganho de performance massivo sobre o modelo estat√≠stico:
- **Redu√ß√£o do MSE:** 91.78% ‚¨áÔ∏è
- **Redu√ß√£o do RMSE:** 71.33% ‚¨áÔ∏è
- **Aumento do R¬≤:** De 0.02 para **0.92** ‚¨ÜÔ∏è

## üß™ An√°lise dos Resultados

- **Captura de Tend√™ncia:** enquanto o ARIMA tendeu a projetar uma linha mais r√≠gida (superestimando o crescimento linear e falhando em capturar a curvatura exata), a **LSTM** conseguiu aprender a din√¢mica n√£o linear e a in√©rcia da s√©rie.
- **Ader√™ncia aos Dados:** o gr√°fico de teste revelou que a LSTM acompanhou muito bem as oscila√ß√µes recentes, resultando em um coeficiente de determina√ß√£o (**R¬≤**) de **0.92**, o que indica que o modelo explica 92% da variabilidade dos dados de teste.
- **Suaviza√ß√£o:** o modelo de ML suavizou alguns picos extremos, mas manteve a dire√ß√£o geral da s√©rie com muito mais precis√£o do que os m√©todos cl√°ssicos.

## üß≠ Conclus√£o

Este projeto demonstrou a superioridade das **Redes Neurais Recorrentes (LSTM)** para esta s√©rie temporal espec√≠fica em compara√ß√£o aos m√©todos estat√≠sticos tradicionais.

> **Em s√≠ntese:**
> A capacidade da LSTM de reter mem√≥rias de sequ√™ncias passadas e modelar n√£o-linearidades permitiu reduzir o erro quadr√°tico m√©dio em mais de **90%** em rela√ß√£o ao ARIMA. Isso refor√ßa a ideia de que, para s√©ries temporais complexas e com padr√µes n√£o lineares, as abordagens de Machine Learning podem oferecer vantagens sobre os m√©todos estat√≠sticos convencionais.

## üöÄ Como rodar

### 1) Pr√©-requisitos
- Python 3.10+ (recomendado 3.11)
- Git (opcional para clonar o reposit√≥rio)

### 2) Clonar o reposit√≥rio
Clone o reposit√≥rio oficial do projeto a partir do GitHub:

```bash
git clone https://github.com/thaisaraujom/PPGEEC2327-time-series
cd PPGEEC2327-time-series
```

### 3) Criar e ativar o ambiente virtual
```bash
# macOS / Linux
python -m venv .venv
source .venv/bin/activate

# Windows (PowerShell)
python -m venv .venv
.venv\Scripts\Activate.ps1
```

### 4) ‚ö†Ô∏è Organiza√ß√£o dos Arquivos (Importante)
Para que o notebook execute corretamente as compara√ß√µes, certifique-se de que os seguintes arquivos estejam **no mesmo diret√≥rio (pasta)** do arquivo `lstm.ipynb`:

* `lstm.ipynb`: o notebook principal.
* `co2_emissions_processed.csv`: o dataset pr√©-processado.
* `fc_arima_log.npy`: o arquivo com as previs√µes salvas do modelo ARIMA (necess√°rio para o gr√°fico comparativo).

> **Nota:** N√£o coloque estes arquivos em subpastas (como `data/`), pois o c√≥digo espera encontr√°-los na raiz de execu√ß√£o.

### 5) **Instalar as depend√™ncias a partir do `requirements.txt`:**
O comando a seguir instalar√° todas as bibliotecas necess√°rias de uma s√≥ vez.
```bash
pip install -r requirements.txt
```

### 6) Execu√ß√£o do Notebook
Com o ambiente preparado, voc√™ pode optar pelo **VSCode**, **Google Colab** ou **Jupyter Notebook/Lab** para a execu√ß√£o do projeto.